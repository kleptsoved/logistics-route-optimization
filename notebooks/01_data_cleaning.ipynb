{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f94acb33-ecb4-46bd-8119-dd4e34d76b14",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preprocessing\n",
    "\n",
    "## Overview\n",
    "This notebook covers essential steps for preparing raw data before analysis. The goal is to ensure that datasets are structured, free from inconsistencies, and ready for merging or visualization. The steps include:\n",
    "\n",
    "- Handling missing values\n",
    "- Formatting column names\n",
    "- Filtering and removing duplicates\n",
    "- Creating new features if necessary\n",
    "\n",
    "Data cleaning is the first step in any data analysis pipeline, ensuring the integrity and reliability of insights drawn from the dataset.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d45881-cf4f-4299-bada-717618c567ed",
   "metadata": {},
   "source": [
    "## Importing Necessary Libraries\n",
    "This notebook relies primarily on **pandas** for data wrangling and **chardet** for encoding detection.  \n",
    "Visualisation libraries are *not* required at this stage and have been removed to keep the environment lean.\n",
    "- `pandas`: For working with structured data (tables, CSV, Excel)\n",
    "- `numpy`: For numerical computations\n",
    "- `matplotlib` & `seaborn`: For potential visual exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "270e7f05-98e2-4aa1-93aa-8c8ef502dba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data folder: C:\\Users\\User\\Dropbox\\Personal\\CareerFoundry\\06 Sourcing data\\Notebook folder\\03 scripts\n",
      "Input path: C:\\Users\\User\\Dropbox\\Personal\\CareerFoundry\\06 Sourcing data\\Notebook folder\\02 Data\\00_original_data\n",
      "Output path: C:\\Users\\User\\Dropbox\\Personal\\CareerFoundry\\06 Sourcing data\\Notebook folder\\02 Data\\01_processed_data\\01_clean_data\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import chardet\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the relative path of the directory where this script/notebook is located.\n",
    "script_dir = os.getcwd()  # or wherever your notebook is running\n",
    "\n",
    "# Go one level up (to the parent folder) and then into \"02 data\".\n",
    "data_folder = Path.cwd()\n",
    "input_path = data_folder.parent / '02 Data' / '00_original_data'\n",
    "output_path = data_folder.parent / '02 Data' / '01_processed_data' / '01_clean_data'\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "print(\"Data folder:\", data_folder)\n",
    "print(\"Input path:\", input_path)\n",
    "print(\"Output path:\", output_path)\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Force Jupyter Notebook to use all available horizontal space\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.width', 1000)          # Set width to a large number\n",
    "pd.set_option('display.max_colwidth', None)     # Show full column content if needed\n",
    "pd.set_option('display.float_format', lambda x: f\"{x:,.2f}\".replace(',', ' '))  # Format numbers with 2 decimal places"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b4c796-0460-4b29-b17e-c76683312794",
   "metadata": {},
   "source": [
    "### Verify input folder and list available files\n",
    "This cell checks that `input_path` exists and prints the CSV/PKL files that will be processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16c3b308-213b-4c24-b4c4-48e9688effb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available files in the input folder:\n",
      "1. service_types.csv\n",
      "2. weekly_deliveries.csv\n",
      "3. work_time_and_km.csv\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter the file numbers to process (comma-separated), or leave blank to process all files:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Files selected for processing: ['work_time_and_km.csv']\n"
     ]
    }
   ],
   "source": [
    "# Verify the input folder exists and list available files.\n",
    "if not os.path.exists(input_path):\n",
    "    print(f\"Error: The folder '{input_path}' does not exist. Please ensure the base folder is correct.\")\n",
    "else:\n",
    "    available_files = [f for f in os.listdir(input_path)]\n",
    "    print(\"Available files in the input folder:\")\n",
    "    for idx, f in enumerate(available_files, start=1):\n",
    "        print(f\"{idx}. {f}\")\n",
    "    \n",
    "    file_numbers_input = input(\n",
    "        \"\\nEnter the file numbers to process (comma-separated), or leave blank to process all files: \"\n",
    "    ).strip()\n",
    "    \n",
    "    if file_numbers_input:\n",
    "        try:\n",
    "            indices = [int(num.strip()) for num in file_numbers_input.split(',') if num.strip()]\n",
    "            # Validate indices and build the list of selected files.\n",
    "            files_list = [available_files[i-1] for i in indices if 1 <= i <= len(available_files)]\n",
    "            if not files_list:\n",
    "                print(\"No valid file numbers were entered.\")\n",
    "        except ValueError:\n",
    "            print(\"Error: Please enter valid numbers separated by commas.\")\n",
    "            files_list = []\n",
    "    else:\n",
    "        files_list = available_files\n",
    "\n",
    "    print(\"\\nFiles selected for processing:\", files_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b67f4d-22a2-44f4-abd2-8cc422153247",
   "metadata": {},
   "source": [
    "### Initialize report generation variables\n",
    "These variables will be used to track processing statistics and generate a summary report.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f2dc68b-1643-4c96-a357-f7c3f0d4721b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting report generation\n",
    "summary_lines = []\n",
    "current_file = files_list[0]  # Get the first file from the list of selected files\n",
    "file_path = os.path.join(input_path, current_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a75ff2-16b0-4d32-964f-43d6279e816a",
   "metadata": {},
   "source": [
    "### Helper – `preview_csv_with_delimiters`\n",
    "Detect encoding & delimiter by sampling the first lines of a CSV. Returns a pandas DataFrame or raises `FileNotFoundError`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dbffc99-7039-4b72-af7b-9efd7a14ea41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing CSV file: work_time_and_km.csv\n",
      "Detected encoding: UTF-8-SIG\n",
      "\n",
      "Preview using delimiter ',':\n",
      "Failed with delimiter ','. Error: Error tokenizing data. C error: Expected 2 fields in line 3, saw 3\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Preview using delimiter ';':\n",
      "         Date  Year  Month  Day  Route  Route_id Start_time  end_time   time distance\n",
      "0  17.03.2025  2025      3   17    102         2   09:00:00  19:25:00  10,42      115\n",
      "1  18.03.2025  2025      3   18    202         2   09:34:00  19:02:00   9,47    53,19\n",
      "2  19.03.2025  2025      3   19    302         2   08:22:00  17:36:00   9,23    49,32\n",
      "--------------------------------------------------\n",
      "\n",
      "Preview using delimiter '\\t':\n",
      "  Date;Year;Month;Day;Route;Route_id;Start_time;end_time;time;distance\n",
      "0               17.03.2025;2025;3;17;102;2;09:00:00;19:25:00;10,42;115\n",
      "1              18.03.2025;2025;3;18;202;2;09:34:00;19:02:00;9,47;53,19\n",
      "2              19.03.2025;2025;3;19;302;2;08:22:00;17:36:00;9,23;49,32\n",
      "--------------------------------------------------\n",
      "\n",
      "Preview using delimiter '|':\n",
      "  Date;Year;Month;Day;Route;Route_id;Start_time;end_time;time;distance\n",
      "0               17.03.2025;2025;3;17;102;2;09:00:00;19:25:00;10,42;115\n",
      "1              18.03.2025;2025;3;18;202;2;09:34:00;19:02:00;9,47;53,19\n",
      "2              19.03.2025;2025;3;19;302;2;08:22:00;17:36:00;9,23;49,32\n",
      "--------------------------------------------------\n",
      "\n",
      "Select the correct delimiter from the options below:\n",
      "1. ','\n",
      "2. ';'\n",
      "3. '\\t'\n",
      "4. '|'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the number corresponding to the correct delimiter:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 'work_time_and_km.csv' with delimiter ';' (rows: 20, columns: 10)\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def preview_csv_with_delimiters(file_path, \n",
    "                                fallback_encodings=['latin1', 'ISO-8859-1', 'cp1252'], \n",
    "                                possible_delimiters=[',', ';', '\\t', '|']):\n",
    "    \"\"\"\n",
    "    Detects the file encoding, then previews the first 3 rows of the CSV using various delimiters.\n",
    "    Returns the detected encoding and a dictionary of previews keyed by delimiter.\n",
    "    \"\"\"\n",
    "    # Detect encoding using a sample from the file.\n",
    "    with open(file_path, 'rb') as f:\n",
    "        rawdata = f.read(100000)  # Read first 100k bytes\n",
    "    detection = chardet.detect(rawdata)\n",
    "    encoding = detection.get('encoding', 'utf-8')\n",
    "    print(f\"Detected encoding: {encoding}\\n\")\n",
    "    \n",
    "    previews = {}\n",
    "    for delim in possible_delimiters:\n",
    "        print(f\"Preview using delimiter {repr(delim)}:\")\n",
    "        try:\n",
    "            # Read only the first 3 rows for preview\n",
    "            df_preview = pd.read_csv(file_path, encoding=encoding, sep=delim, nrows=3)\n",
    "            previews[delim] = df_preview\n",
    "            print(df_preview)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed with delimiter {repr(delim)}. Error: {e}\")\n",
    "        print(\"-\" * 50 + \"\\n\")\n",
    "    return encoding, previews\n",
    "\n",
    "# Dictionary to store the DataFrames for each file.\n",
    "df = {}\n",
    "\n",
    "for file in files_list:\n",
    "    file_path = os.path.join(input_path, file)\n",
    "    if os.path.exists(file_path):\n",
    "        if file.endswith('.csv'):\n",
    "            print(f\"Processing CSV file: {file}\")\n",
    "            # Preview the CSV with different delimiters.\n",
    "            encoding, previews = preview_csv_with_delimiters(file_path)\n",
    "            \n",
    "            # List the delimiter options with numbers.\n",
    "            possible_delimiters = [',', ';', '\\t', '|']\n",
    "            print(\"Select the correct delimiter from the options below:\")\n",
    "            for idx, delim in enumerate(possible_delimiters, start=1):\n",
    "                print(f\"{idx}. {repr(delim)}\")\n",
    "            \n",
    "            # Ask the user to choose the correct delimiter by number.\n",
    "            while True:\n",
    "                try:\n",
    "                    selected_number = int(input(\"Enter the number corresponding to the correct delimiter: \"))\n",
    "                    if 1 <= selected_number <= len(possible_delimiters):\n",
    "                        selected_delim = possible_delimiters[selected_number - 1]\n",
    "                        break\n",
    "                    else:\n",
    "                        print(\"Invalid number. Please choose a valid option.\")\n",
    "                except ValueError:\n",
    "                    print(\"Please enter a valid integer.\")\n",
    "            \n",
    "            # Now load the full CSV using the selected delimiter.\n",
    "            try:\n",
    "                df_csv = pd.read_csv(file_path, encoding=encoding, sep=selected_delim)\n",
    "                df[file] = df_csv\n",
    "                print(f\"Successfully loaded '{file}' with delimiter {repr(selected_delim)} \" \\\n",
    "                      f\"(rows: {df_csv.shape[0]}, columns: {df_csv.shape[1]})\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading CSV file {file} with delimiter {repr(selected_delim)}: {e}\")\n",
    "                continue\n",
    "        elif file.endswith('.pkl'):\n",
    "            try:\n",
    "                df[file] = pd.read_pickle(file_path)\n",
    "                print(f\"Loaded pickle file '{file}' (rows: {df[file].shape[0]}, columns: {df[file].shape[1]})\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading pickle file {file}: {e}\")\n",
    "                continue\n",
    "        else:\n",
    "            print(f\"Skipping unsupported file format: {file}\")\n",
    "            continue\n",
    "        \n",
    "        print(\"=\" * 100 + \"\\n\")\n",
    "    else:\n",
    "        print(f\"File {file} not found and will be skipped.\")\n",
    "\n",
    "# Logging details.\n",
    "report_details = [f\"File: {current_file}\"]\n",
    "report_details.append(f\"Total loaded files: {len(df)}\")\n",
    "modifications = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3e58be-1062-4eed-b85c-5c3e1d27d8f3",
   "metadata": {},
   "source": [
    "### Quick HTML preview of all loaded DataFrames\n",
    "Shows the first two rows of every imported file for a visual sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30ee9f50-f85d-4feb-905e-a8ecc86642ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>work_time_and_km.csv</h4><div style=\"overflow-x: auto; width:100%;\"><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Route</th>\n",
       "      <th>Route_id</th>\n",
       "      <th>Start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>time</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.03.2025</td>\n",
       "      <td>2025</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>19:25:00</td>\n",
       "      <td>10,42</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21.03.2025</td>\n",
       "      <td>2025</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>543</td>\n",
       "      <td>43</td>\n",
       "      <td>10:56:00</td>\n",
       "      <td>15:44:00</td>\n",
       "      <td>4,8</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# present all imported DataFrames\n",
    "\n",
    "for file_name, data in df.items():\n",
    "    html = data.to_html(max_rows=2, max_cols=30)\n",
    "    display(HTML(f'<h4>{file_name}</h4><div style=\"overflow-x: auto; width:100%;\">{html}</div>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52909e90-6b78-457d-be7e-9b4b3254aed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[current_file].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42937cd3-8a68-4989-82b5-1d6066dec31e",
   "metadata": {},
   "source": [
    "## Handling Missing Values\n",
    "Missing data can affect analysis accuracy. This section explores strategies such as:\n",
    "- Removing rows/columns with excessive missing values\n",
    "- Imputing missing values based on statistical methods\n",
    "- Using placeholders for unknown values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db376776-3205-4603-a0cf-a7c94c90fc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter columns to exclude (comma-separated), or press Enter to skip:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No columns were excluded.\n"
     ]
    }
   ],
   "source": [
    "# Data Customization – Exclude Columns\n",
    "df[current_file].head()\n",
    "data = df[current_file]\n",
    "data.head()\n",
    "exclude_cols_input = input(\"\\nEnter columns to exclude (comma-separated), or press Enter to skip: \").strip()\n",
    "if exclude_cols_input:\n",
    "    exclude_cols = [col.strip() for col in exclude_cols_input.split(',') if col.strip()]\n",
    "    data = data.drop(columns=exclude_cols, errors='ignore')\n",
    "    modifications.append(f\"Excluded columns: {', '.join(exclude_cols)}\")\n",
    "    print(f\"Columns excluded: {exclude_cols}\")\n",
    "else:\n",
    "    print(\"No columns were excluded.\")\n",
    "\n",
    "# Update the DataFrame in the dictionary.\n",
    "df[current_file] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9ccd0d-e9d0-43cd-b5b7-deb5e76f4316",
   "metadata": {},
   "source": [
    "## Formatting and Standardizing Column Names\n",
    "To ensure consistency across datasets, column names are standardized:\n",
    "- Converted to lowercase\n",
    "- Replacing spaces with underscores\n",
    "- Removing special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1338824-ed2e-4497-be04-615c6499cfc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current column names:\n",
      "['Date', 'Year', 'Month', 'Day', 'Route', 'Route_id', 'Start_time', 'end_time', 'time', 'distance']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter column name to rename, or press Enter to stop renaming:  \n"
     ]
    }
   ],
   "source": [
    "# Data Customization – Rename Columns\n",
    "while True:\n",
    "    print(\"\\nCurrent column names:\")\n",
    "    print(list(data.columns))\n",
    "    col_to_rename = input(\"Enter column name to rename, or press Enter to stop renaming: \").strip()\n",
    "    if not col_to_rename:\n",
    "        break\n",
    "    if col_to_rename in data.columns:\n",
    "        new_name = input(f\"Enter new name for column '{col_to_rename}': \").strip()\n",
    "        data.rename(columns={col_to_rename: new_name}, inplace=True)\n",
    "        modifications.append(f\"Renamed column '{col_to_rename}' to '{new_name}'\")\n",
    "        print(f\"Renamed '{col_to_rename}' to '{new_name}'\")\n",
    "    else:\n",
    "        print(f\"Column '{col_to_rename}' not found.\")\n",
    "        \n",
    "df[current_file] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e807c8c2-bd0a-490e-bace-d0296dffc2f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns:\n",
      "1. Date (current dtype: object)\n",
      "2. Year (current dtype: int64)\n",
      "3. Month (current dtype: int64)\n",
      "4. Day (current dtype: int64)\n",
      "5. Route (current dtype: int64)\n",
      "6. Route_id (current dtype: int64)\n",
      "7. Start_time (current dtype: object)\n",
      "8. end_time (current dtype: object)\n",
      "9. time (current dtype: object)\n",
      "10. distance (current dtype: object)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter the column number to change data type, or press Enter to stop:\n",
      " 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available data types:\n",
      "1. int - Integer (no decimal part). E.g. 42\n",
      "2. float - Floating-point number (decimal allowed). E.g. 3.14\n",
      "3. str - String (text). E.g. 'Hello world'\n",
      "4. bool - Boolean (True or False)\n",
      "5. datetime64[ns] - Date and time in Pandas datetime format\n",
      "6. category - Categorical data (saves memory if repetitive values)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter the number corresponding to the desired data type for 'Date':\n",
      " 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed data type of 'Date' to datetime64[ns]\n",
      "\n",
      "Columns:\n",
      "1. Date (current dtype: datetime64[ns])\n",
      "2. Year (current dtype: int64)\n",
      "3. Month (current dtype: int64)\n",
      "4. Day (current dtype: int64)\n",
      "5. Route (current dtype: int64)\n",
      "6. Route_id (current dtype: int64)\n",
      "7. Start_time (current dtype: object)\n",
      "8. end_time (current dtype: object)\n",
      "9. time (current dtype: object)\n",
      "10. distance (current dtype: object)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter the column number to change data type, or press Enter to stop:\n",
      " 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available data types:\n",
      "1. int - Integer (no decimal part). E.g. 42\n",
      "2. float - Floating-point number (decimal allowed). E.g. 3.14\n",
      "3. str - String (text). E.g. 'Hello world'\n",
      "4. bool - Boolean (True or False)\n",
      "5. datetime64[ns] - Date and time in Pandas datetime format\n",
      "6. category - Categorical data (saves memory if repetitive values)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter the number corresponding to the desired data type for 'Start_time':\n",
      " 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed data type of 'Start_time' to datetime64[ns]\n",
      "\n",
      "Columns:\n",
      "1. Date (current dtype: datetime64[ns])\n",
      "2. Year (current dtype: int64)\n",
      "3. Month (current dtype: int64)\n",
      "4. Day (current dtype: int64)\n",
      "5. Route (current dtype: int64)\n",
      "6. Route_id (current dtype: int64)\n",
      "7. Start_time (current dtype: datetime64[ns])\n",
      "8. end_time (current dtype: object)\n",
      "9. time (current dtype: object)\n",
      "10. distance (current dtype: object)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter the column number to change data type, or press Enter to stop:\n",
      " 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available data types:\n",
      "1. int - Integer (no decimal part). E.g. 42\n",
      "2. float - Floating-point number (decimal allowed). E.g. 3.14\n",
      "3. str - String (text). E.g. 'Hello world'\n",
      "4. bool - Boolean (True or False)\n",
      "5. datetime64[ns] - Date and time in Pandas datetime format\n",
      "6. category - Categorical data (saves memory if repetitive values)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter the number corresponding to the desired data type for 'end_time':\n",
      " 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed data type of 'end_time' to datetime64[ns]\n",
      "\n",
      "Columns:\n",
      "1. Date (current dtype: datetime64[ns])\n",
      "2. Year (current dtype: int64)\n",
      "3. Month (current dtype: int64)\n",
      "4. Day (current dtype: int64)\n",
      "5. Route (current dtype: int64)\n",
      "6. Route_id (current dtype: int64)\n",
      "7. Start_time (current dtype: datetime64[ns])\n",
      "8. end_time (current dtype: datetime64[ns])\n",
      "9. time (current dtype: object)\n",
      "10. distance (current dtype: object)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter the column number to change data type, or press Enter to stop:\n",
      " 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available data types:\n",
      "1. int - Integer (no decimal part). E.g. 42\n",
      "2. float - Floating-point number (decimal allowed). E.g. 3.14\n",
      "3. str - String (text). E.g. 'Hello world'\n",
      "4. bool - Boolean (True or False)\n",
      "5. datetime64[ns] - Date and time in Pandas datetime format\n",
      "6. category - Categorical data (saves memory if repetitive values)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter the number corresponding to the desired data type for 'time':\n",
      " 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to change data type of 'time' to float: could not convert string to float: '10,42'\n",
      "\n",
      "Attempting to auto-clean the 'time' column for float conversion...\n",
      "\n",
      "Preview of original vs. converted values (first 5 rows):\n",
      "  original  converted\n",
      "0    10,42      10.42\n",
      "1     9,47       9.47\n",
      "2     9,23       9.23\n",
      "3     9,48       9.48\n",
      "4     9,17       9.17\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Does this look correct? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully auto-cleaned and changed data type of 'time' to float\n",
      "\n",
      "Columns:\n",
      "1. Date (current dtype: datetime64[ns])\n",
      "2. Year (current dtype: int64)\n",
      "3. Month (current dtype: int64)\n",
      "4. Day (current dtype: int64)\n",
      "5. Route (current dtype: int64)\n",
      "6. Route_id (current dtype: int64)\n",
      "7. Start_time (current dtype: datetime64[ns])\n",
      "8. end_time (current dtype: datetime64[ns])\n",
      "9. time (current dtype: float64)\n",
      "10. distance (current dtype: object)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter the column number to change data type, or press Enter to stop:\n",
      " 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available data types:\n",
      "1. int - Integer (no decimal part). E.g. 42\n",
      "2. float - Floating-point number (decimal allowed). E.g. 3.14\n",
      "3. str - String (text). E.g. 'Hello world'\n",
      "4. bool - Boolean (True or False)\n",
      "5. datetime64[ns] - Date and time in Pandas datetime format\n",
      "6. category - Categorical data (saves memory if repetitive values)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter the number corresponding to the desired data type for 'distance':\n",
      " 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to change data type of 'distance' to float: could not convert string to float: '53,19'\n",
      "\n",
      "Attempting to auto-clean the 'distance' column for float conversion...\n",
      "\n",
      "Preview of original vs. converted values (first 5 rows):\n",
      "  original  converted\n",
      "0      115     115.00\n",
      "1    53,19      53.19\n",
      "2    49,32      49.32\n",
      "3    43,14      43.14\n",
      "4   101,08     101.08\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Does this look correct? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully auto-cleaned and changed data type of 'distance' to float\n",
      "\n",
      "Columns:\n",
      "1. Date (current dtype: datetime64[ns])\n",
      "2. Year (current dtype: int64)\n",
      "3. Month (current dtype: int64)\n",
      "4. Day (current dtype: int64)\n",
      "5. Route (current dtype: int64)\n",
      "6. Route_id (current dtype: int64)\n",
      "7. Start_time (current dtype: datetime64[ns])\n",
      "8. end_time (current dtype: datetime64[ns])\n",
      "9. time (current dtype: float64)\n",
      "10. distance (current dtype: float64)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter the column number to change data type, or press Enter to stop:\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Example function to clean currency-like strings and convert to float\n",
    "def parse_currency_string(value):\n",
    "    \"\"\"\n",
    "    Attempts to remove currency symbols, spaces, and convert commas to dots,\n",
    "    then parses the result as a float. Leaves NaNs as NaN.\n",
    "    \"\"\"\n",
    "    if pd.isna(value):\n",
    "        return value  # Keep NaNs as is\n",
    "    # Remove '$' if present (or other currency symbols)\n",
    "    value = str(value).replace('$', '')\n",
    "    # Remove spaces\n",
    "    value = value.replace(' ', '')\n",
    "    # Replace comma with dot (assuming comma decimal format)\n",
    "    value = value.replace(',', '.')\n",
    "    # Convert to float\n",
    "    return float(value)\n",
    "\n",
    "# List of available data types (key + explanation)\n",
    "available_dtypes = [\n",
    "    ('int', \"Integer (no decimal part). E.g. 42\"),\n",
    "    ('float', \"Floating-point number (decimal allowed). E.g. 3.14\"),\n",
    "    ('str', \"String (text). E.g. 'Hello world'\"),\n",
    "    ('bool', \"Boolean (True or False)\"),\n",
    "    ('datetime64[ns]', \"Date and time in Pandas datetime format\"),\n",
    "    ('category', \"Categorical data (saves memory if repetitive values)\"),\n",
    "]\n",
    "\n",
    "# Data Customization – Change Data Types by column number\n",
    "while True:\n",
    "    \n",
    "    # Number each column\n",
    "    columns_list = list(data.columns)\n",
    "    print(\"\\nColumns:\")\n",
    "    for i, col in enumerate(columns_list, start=1):\n",
    "        print(f\"{i}. {col} (current dtype: {data[col].dtype})\")\n",
    "    \n",
    "    # Ask user which column to convert by number\n",
    "    col_number_input = input(\"\\nEnter the column number to change data type, or press Enter to stop:\\n\").strip()\n",
    "    if not col_number_input:\n",
    "        break  # Stop if user presses Enter without a choice\n",
    "    \n",
    "    try:\n",
    "        col_number = int(col_number_input)\n",
    "        if 1 <= col_number <= len(columns_list):\n",
    "            col_to_cast = columns_list[col_number - 1]\n",
    "        else:\n",
    "            print(\"Invalid column number. Please try again.\")\n",
    "            continue\n",
    "    except ValueError:\n",
    "        print(\"Please enter a valid integer for the column number.\")\n",
    "        continue\n",
    "    \n",
    "    # Show available data types by number\n",
    "    print(\"\\nAvailable data types:\")\n",
    "    for idx, (dt_key, dt_expl) in enumerate(available_dtypes, start=1):\n",
    "        print(f\"{idx}. {dt_key} - {dt_expl}\")\n",
    "    \n",
    "    # Ask user for the new data type by number\n",
    "    dtype_choice = input(f\"\\nEnter the number corresponding to the desired data type for '{col_to_cast}':\\n\").strip()\n",
    "    try:\n",
    "        dtype_choice_num = int(dtype_choice)\n",
    "        if 1 <= dtype_choice_num <= len(available_dtypes):\n",
    "            new_dtype = available_dtypes[dtype_choice_num - 1][0]\n",
    "        else:\n",
    "            print(\"Invalid number. Please choose a valid option.\")\n",
    "            continue\n",
    "    except ValueError:\n",
    "        print(\"Please enter a valid integer.\")\n",
    "        continue\n",
    "    \n",
    "    # Try direct casting first\n",
    "    try:\n",
    "        data[col_to_cast] = data[col_to_cast].astype(new_dtype)\n",
    "        modifications.append(f\"Changed data type of '{col_to_cast}' to {new_dtype}\")\n",
    "        print(f\"Changed data type of '{col_to_cast}' to {new_dtype}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to change data type of '{col_to_cast}' to {new_dtype}: {e}\")\n",
    "        \n",
    "        # Attempt auto-clean only if user wants int or float\n",
    "        if new_dtype in [\"int\", \"float\"]:\n",
    "            print(f\"\\nAttempting to auto-clean the '{col_to_cast}' column for {new_dtype} conversion...\")\n",
    "\n",
    "            try:\n",
    "                # 1. Clean the column (remove currency symbols, fix decimal separators, etc.)\n",
    "                temp_col = data[col_to_cast].apply(parse_currency_string)\n",
    "                \n",
    "                # 2. Handle missing values before casting to int/float\n",
    "                missing_count = temp_col.isna().sum()\n",
    "                if missing_count > 0:\n",
    "                    print(f\"Found {missing_count} missing (NaN) values in '{col_to_cast}'.\")\n",
    "                    print(\"How would you like to handle these missing values?\")\n",
    "                    print(\"1. Drop rows with missing values\")\n",
    "                    print(\"2. Fill missing values with 0\")\n",
    "                    print(\"3. Fill missing values with a custom value\")\n",
    "                    print(\"4. Leave them as NaN (only works for float)\")\n",
    "                    mv_choice = input(\"Enter the number of your choice (1/2/3/4): \").strip()\n",
    "                    \n",
    "                    if mv_choice == \"1\":\n",
    "                        temp_col = temp_col.dropna()\n",
    "                        print(\"Dropped rows with missing values.\")\n",
    "                    elif mv_choice == \"2\":\n",
    "                        temp_col = temp_col.fillna(0)\n",
    "                        print(\"Filled missing values with 0.\")\n",
    "                    elif mv_choice == \"3\":\n",
    "                        fill_val = input(\"Enter the value to fill missing values: \")\n",
    "                        # Convert fill_val to the appropriate numeric type\n",
    "                        if new_dtype == \"float\":\n",
    "                            fill_val = float(fill_val)\n",
    "                        elif new_dtype == \"int\":\n",
    "                            fill_val = int(float(fill_val))  # in case user typed \"3.0\"\n",
    "                        temp_col = temp_col.fillna(fill_val)\n",
    "                        print(f\"Filled missing values with '{fill_val}'.\")\n",
    "                    elif mv_choice == \"4\":\n",
    "                        if new_dtype == \"float\":\n",
    "                            print(\"Leaving missing values as NaN.\")\n",
    "                        else:\n",
    "                            print(\"Cannot leave NaN if converting to int. Attempting fill with 0.\")\n",
    "                            temp_col = temp_col.fillna(0)\n",
    "                    else:\n",
    "                        print(\"Invalid choice. Leaving missing values as NaN for now.\")\n",
    "                \n",
    "                # 3. Convert to float or int as requested\n",
    "                if new_dtype == \"int\":\n",
    "                    temp_col = temp_col.astype(int)\n",
    "                else:\n",
    "                    temp_col = temp_col.astype(float)\n",
    "                \n",
    "                # 4. Show side-by-side comparison for first 5 rows\n",
    "                comparison_df = pd.DataFrame({\n",
    "                    \"original\": data[col_to_cast].head(5),\n",
    "                    \"converted\": temp_col.head(5)\n",
    "                })\n",
    "                \n",
    "                print(\"\\nPreview of original vs. converted values (first 5 rows):\")\n",
    "                print(comparison_df)\n",
    "                \n",
    "                # 5. Prompt user confirmation\n",
    "                confirm = input(\"\\nDoes this look correct? (y/n): \").strip().lower()\n",
    "                if confirm == \"y\":\n",
    "                    # If we dropped rows, we need to align the main DataFrame with temp_col’s index\n",
    "                    data = data.reindex(temp_col.index)  # In case some rows were dropped\n",
    "                    data[col_to_cast] = temp_col\n",
    "                    modifications.append(f\"Auto-cleaned and changed data type of '{col_to_cast}' to {new_dtype}\")\n",
    "                    print(f\"Successfully auto-cleaned and changed data type of '{col_to_cast}' to {new_dtype}\")\n",
    "                else:\n",
    "                    print(\"No changes applied.\")\n",
    "            \n",
    "            except Exception as e2:\n",
    "                print(f\"Auto-cleaning also failed: {e2}\")\n",
    "        else:\n",
    "            print(\"Auto-cleaning is only implemented for int or float conversions.\")\n",
    "\n",
    "# Finally, store the updated DataFrame back if needed\n",
    "df[current_file] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a46227f-bffa-4fa5-847f-0506871db57c",
   "metadata": {},
   "source": [
    "### Handle missing values + outlier detection\n",
    "Runs per-column NaN checks, prints summary, and detects IQR-based outliers in numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5df8c273-79a8-458f-9373-714bfd718cb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for missing values...\n",
      "No missing values detected.\n"
     ]
    }
   ],
   "source": [
    "# # Checking for missing values in the dataset\n",
    "print(\"\\nChecking for missing values...\")\n",
    "missing_summary = data.isnull().sum()\n",
    "missing_summary = missing_summary[missing_summary > 0]\n",
    "rows_before = len(data)\n",
    "\n",
    "if not missing_summary.empty:\n",
    "    print(\"Columns with missing values and their counts:\")\n",
    "    print(missing_summary)\n",
    "    \n",
    "    print(\"\\nColumn statistics:\")\n",
    "    display(data.describe())\n",
    "    \n",
    "    # Loop through each column that has missing values\n",
    "    for column in missing_summary.index:\n",
    "        # Display the first 5 rows where the current column has missing values\n",
    "        print(f\"\\nFirst 5 rows where '{column}' is missing:\")\n",
    "        display(data[data[column].isnull()].head())\n",
    "        \n",
    "        fill_method = input(\n",
    "            f\"Enter method to handle missing values for '{column}' \"\n",
    "            \"(mean, median, drop, or custom value), or press Enter to skip: \"\n",
    "        ).strip()\n",
    "        \n",
    "        if fill_method == 'mean':\n",
    "            data[column] = data[column].fillna(data[column].mean())\n",
    "            modifications.append(f\"Filled missing values in '{column}' with mean\")\n",
    "        \n",
    "        elif fill_method == 'median':\n",
    "            data[column] = data[column].fillna(data[column].median())\n",
    "            modifications.append(f\"Filled missing values in '{column}' with median\")\n",
    "        \n",
    "        elif fill_method == 'drop':\n",
    "            data.dropna(subset=[column], inplace=True)\n",
    "            modifications.append(f\"Dropped rows with missing values in '{column}'\")\n",
    "        \n",
    "        elif fill_method:\n",
    "            try:\n",
    "                if data[column].dtype.kind in 'fc':  # numeric types\n",
    "                    value = float(fill_method)\n",
    "                else:\n",
    "                    value = fill_method\n",
    "                \n",
    "                data[column] = data[column].fillna(value)\n",
    "                modifications.append(f\"Filled missing values in '{column}' with custom value: {value}\")\n",
    "            \n",
    "            except ValueError:\n",
    "                print(f\"Invalid custom value for '{column}', skipping...\")\n",
    "else:\n",
    "    print(\"No missing values detected.\")\n",
    "\n",
    "rows_after = len(data)\n",
    "report_details.append(f\"Rows dropped due to missing values: {rows_before - rows_after}\")\n",
    "\n",
    "df[current_file] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c53565-6c33-4bd0-b583-f597dd8099c3",
   "metadata": {},
   "source": [
    "### Duplicate row management\n",
    "Identify and optionally drop exact duplicates, reporting the count removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e518e445-76a6-4bca-8ce8-dec5de8836b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for duplicate rows...\n",
      "Found 0 duplicate rows.\n"
     ]
    }
   ],
   "source": [
    "# Duplicate Row Management\n",
    "\n",
    "print(\"\\nChecking for duplicate rows...\")\n",
    "duplicates = data.duplicated().sum()\n",
    "print(f\"Found {duplicates} duplicate rows.\")\n",
    "report_details.append(f\"Number of duplicate rows: {duplicates}\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    print(\"Preview of duplicate rows:\")\n",
    "    display(data[data.duplicated()].head())\n",
    "    drop_dup = input(\"Do you want to drop duplicates? (yes/no): \").strip().lower()\n",
    "    if drop_dup == 'yes':\n",
    "        rows_before_dup = len(data)\n",
    "        data.drop_duplicates(inplace=True)\n",
    "        rows_after_dup = len(data)\n",
    "        modifications.append(\"Dropped duplicate rows\")\n",
    "        report_details.append(f\"Rows dropped due to duplicates: {rows_before_dup - rows_after_dup}\")\n",
    "        print(\"Duplicates dropped.\")\n",
    "    else:\n",
    "        print(\"Duplicates not dropped.\")\n",
    "        \n",
    "df[current_file] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05877aa1-1eb6-4a6f-ab36-4c4c85138a8b",
   "metadata": {},
   "source": [
    "### Outlier detection with the IQR rule  \n",
    "For every numeric column, compute quartiles and flag observations lying outside **[Q1 – 1.5 × IQR, Q3 + 1.5 × IQR]**. Store counts per column for reporting and preview the first offending rows.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "056396d7-aaa2-4ce6-80c1-b12ade014be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detecting outliers in numeric columns...\n",
      "Column 'Route_id': 5 outlier rows detected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Route</th>\n",
       "      <th>Route_id</th>\n",
       "      <th>Start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>time</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03-17</td>\n",
       "      <td>2025</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-05-16 09:00:00</td>\n",
       "      <td>2025-05-16 19:25:00</td>\n",
       "      <td>10.42</td>\n",
       "      <td>115.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-03-18</td>\n",
       "      <td>2025</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>202</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-05-16 09:34:00</td>\n",
       "      <td>2025-05-16 19:02:00</td>\n",
       "      <td>9.47</td>\n",
       "      <td>53.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>2025</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>302</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-05-16 08:22:00</td>\n",
       "      <td>2025-05-16 17:36:00</td>\n",
       "      <td>9.23</td>\n",
       "      <td>49.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-03-20</td>\n",
       "      <td>2025</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>402</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-05-16 08:32:00</td>\n",
       "      <td>2025-05-16 18:01:00</td>\n",
       "      <td>9.48</td>\n",
       "      <td>43.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-03-21</td>\n",
       "      <td>2025</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>502</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-05-16 07:30:00</td>\n",
       "      <td>2025-05-16 16:40:00</td>\n",
       "      <td>9.17</td>\n",
       "      <td>101.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Year  Month  Day  Route  Route_id          Start_time            end_time  time  distance\n",
       "0 2025-03-17  2025      3   17    102         2 2025-05-16 09:00:00 2025-05-16 19:25:00 10.42    115.00\n",
       "1 2025-03-18  2025      3   18    202         2 2025-05-16 09:34:00 2025-05-16 19:02:00  9.47     53.19\n",
       "2 2025-03-19  2025      3   19    302         2 2025-05-16 08:22:00 2025-05-16 17:36:00  9.23     49.32\n",
       "3 2025-03-20  2025      3   20    402         2 2025-05-16 08:32:00 2025-05-16 18:01:00  9.48     43.14\n",
       "4 2025-03-21  2025      3   21    502         2 2025-05-16 07:30:00 2025-05-16 16:40:00  9.17    101.08"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'time': 4 outlier rows detected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Route</th>\n",
       "      <th>Route_id</th>\n",
       "      <th>Start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>time</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2025-03-17</td>\n",
       "      <td>2025</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>143</td>\n",
       "      <td>43</td>\n",
       "      <td>2025-05-16 13:30:00</td>\n",
       "      <td>2025-05-16 17:15:00</td>\n",
       "      <td>3.75</td>\n",
       "      <td>31.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2025-03-18</td>\n",
       "      <td>2025</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>243</td>\n",
       "      <td>43</td>\n",
       "      <td>2025-05-16 08:00:00</td>\n",
       "      <td>2025-05-16 20:21:00</td>\n",
       "      <td>12.35</td>\n",
       "      <td>74.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2025-03-20</td>\n",
       "      <td>2025</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>443</td>\n",
       "      <td>43</td>\n",
       "      <td>2025-05-16 11:46:00</td>\n",
       "      <td>2025-05-16 16:18:00</td>\n",
       "      <td>4.53</td>\n",
       "      <td>56.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2025-03-21</td>\n",
       "      <td>2025</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>543</td>\n",
       "      <td>43</td>\n",
       "      <td>2025-05-16 10:56:00</td>\n",
       "      <td>2025-05-16 15:44:00</td>\n",
       "      <td>4.80</td>\n",
       "      <td>53.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Year  Month  Day  Route  Route_id          Start_time            end_time  time  distance\n",
       "15 2025-03-17  2025      3   17    143        43 2025-05-16 13:30:00 2025-05-16 17:15:00  3.75     31.00\n",
       "16 2025-03-18  2025      3   17    243        43 2025-05-16 08:00:00 2025-05-16 20:21:00 12.35     74.00\n",
       "18 2025-03-20  2025      3   20    443        43 2025-05-16 11:46:00 2025-05-16 16:18:00  4.53     56.00\n",
       "19 2025-03-21  2025      3   21    543        43 2025-05-16 10:56:00 2025-05-16 15:44:00  4.80     53.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'distance': 1 outlier rows detected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Route</th>\n",
       "      <th>Route_id</th>\n",
       "      <th>Start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>time</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03-17</td>\n",
       "      <td>2025</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-05-16 09:00:00</td>\n",
       "      <td>2025-05-16 19:25:00</td>\n",
       "      <td>10.42</td>\n",
       "      <td>115.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Year  Month  Day  Route  Route_id          Start_time            end_time  time  distance\n",
       "0 2025-03-17  2025      3   17    102         2 2025-05-16 09:00:00 2025-05-16 19:25:00 10.42    115.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Outlier Detection\n",
    "\n",
    "print(\"\\nDetecting outliers in numeric columns...\")\n",
    "outliers_info = {}\n",
    "for col in data.select_dtypes(include=['number']).columns:\n",
    "    q1 = data[col].quantile(0.25)\n",
    "    q3 = data[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    outlier_rows = data[(data[col] < lower_bound) | (data[col] > upper_bound)]\n",
    "    if not outlier_rows.empty:\n",
    "        outliers_info[col] = len(outlier_rows)\n",
    "        print(f\"Column '{col}': {len(outlier_rows)} outlier rows detected.\")\n",
    "        display(outlier_rows.head())\n",
    "        \n",
    "if outliers_info:\n",
    "    modifications.append(f\"Outliers detected: {outliers_info}\")\n",
    "    report_details.append(\"Outlier detection completed.\")\n",
    "else:\n",
    "    report_details.append(\"No outliers detected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ea6473-b045-44b7-8a99-ea41ee2a5fca",
   "metadata": {},
   "source": [
    "### Ask for export format (CSV / PKL)\n",
    "Interactive prompt determining output format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5230bda3-c412-4cbb-972f-67100db9cbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter desired output file format (csv or pkl):  csv\n",
      "Enter the desired file name (without extension) or press Enter for 'work_time_and_km_clean':  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Processed file saved to: C:\\Users\\User\\Dropbox\\Personal\\CareerFoundry\\06 Sourcing data\\Notebook folder\\02 Data\\01_processed_data\\01_clean_data\\work_time_and_km_clean.csv\n"
     ]
    }
   ],
   "source": [
    "# Ask user for file format preference: CSV or pkl\n",
    "file_format = input(\"Enter desired output file format (csv or pkl): \").strip().lower()\n",
    "while file_format not in ['csv', 'pkl']:\n",
    "    file_format = input(\"Invalid format. Please enter 'csv' or 'pkl': \").strip().lower()\n",
    "\n",
    "# Create default filename based on original (without extension)\n",
    "original_name_without_ext = os.path.splitext(current_file)[0]\n",
    "default_output_filename = f\"{original_name_without_ext}_clean\"\n",
    "\n",
    "# Prompt for filename but use default if empty\n",
    "output_filename = input(f\"Enter the desired file name (without extension) or press Enter for '{default_output_filename}': \").strip()\n",
    "if not output_filename:\n",
    "    output_filename = default_output_filename\n",
    "\n",
    "output_file = os.path.join(output_path, f\"{output_filename}.{file_format}\")\n",
    "\n",
    "# Save the processed DataFrame in the selected format\n",
    "if file_format == 'csv':\n",
    "    data.to_csv(output_file, index=False)\n",
    "elif file_format == 'pkl':\n",
    "    data.to_pickle(output_file)\n",
    "\n",
    "print(f\"\\n✅ Processed file saved to: {output_file}\")\n",
    "report_details.append(f\"Processed file saved to: {output_file}\")\n",
    "report_details.append(f\"Total rows in the exported file: {len(data)}\")\n",
    "\n",
    "# Update the stored data frame for the current file\n",
    "df[current_file] = data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
